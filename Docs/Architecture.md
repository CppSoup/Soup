
# Architecture

## Overview
The build system **Soup** utilizes a declarative **Recipe** file as an easy to understand definition for an individual Package. This file will be the primary way to tell Soup **what** to build. The core command line application will be used to invoke the build and provide extra configuration parameters. Internally, **Soup** uses a **Task** execution engine to translate the **what** into the **how**. Build Tasks have the ability to express an ordering through a set of before and after named sets. The Tasks will not invoke any build logic themselves, and will instead generate a [Directed Acyclic Graph (DAG)](https://en.wikipedia.org/wiki/Directed_acyclic_graph) of build **Operations** that make up the actual build. These **Operations** will be evaluated to produce the final build result by the system itself to support the ability to track actual input/output files that are accessed during execution for future incremental builds.

## Application
The [Command Line Interface (CLI)](CLI.md) is the first thing a user will see when they interact with the Soup build system. The CLI is primarily there to take user input through a set of parameters and flags to pass temporary configuration values into the build execution. While important, it is fairly straightforward to design and will be left open to evolve through use.

## Definition
The build definition will use a declarative Recipe configuration file is how the user will configure their project. The Recipe file will utilize the [toml](https://github.com/toml-lang/toml) language as a clean, human readable, configuration definition that supports a core set of data types. The file can be thought of as a simple property bag for getting shared parameters passed into the build system for an individual package. There are a few "known" property values that will be used within the build engine itself; however, the entire contents will be provided as initial input to the build engine.

## Engine
The build Engine is responsible for recursively building all transitive dependencies, facilitating the registration and execution of build Tasks, and evaluating all requirement build Operations. All build logic will be contained in Tasks and all build execution will be performed in Operations. Having this extra layer of separation between the build generate and the build evaluate allows for build Extensions to get fast incremental build support for "free" and will allow for future performance improvements without introducing breaking changes into the Extension Framework itself. This means **Soup** can support super fast builds for any possible unique build step or even be extended to support any language by only writing a new default build Extension layer.

This work can be broken down into four phases:
1. **Parse Recipe** -
    The Recipe toml file is read from disk and parsed into a property bag.

2. **Build Dependencies** -
    The Engine will use the known property lists "Dependencies" and "DevDependencies" to recursively build all transitive runtime and development dependencies starting at phase one. The Engine will maintain a communication channel between parent and children project builds, to allow for passing configuration parameters down and output state back up. The active state will initialize special property bag containers that map up to the original "DevDependencies" or "Dependencies" top level table and a sub table for each unique child by name.

3. **Build Generate** -
    The Engine will then discover and invoke a predefined C method that is exported from all registered Extension DLLs. A Build Task will consist of a unique name, lists of other Tasks that must be run before and after, and a single execute entry point. The build Tasks will communicate with the build Engine itself through a strict interface layer to maintain a compatible ABI that will allow the CLI executable to work with the source compiled development dependencies from a different compiler. The build Engine will invoke all registered build Tasks in their requested order as defined by the run Before/After lists. The Tasks can influence each other by reading and writing properties to and from the active state (a shared property bag). A build Task should not actually perform any build commands itself (compile/link/copy/etc.), it will instead generate build Operations which are self contained executable definitions with input/output files.

    A single predefined Extension DLL, that is distributed with the CLI executable, contains the Tasks that execute the default build logic for a given language that will allow for building projects for a majority of scenarios.

    The generate phase will produce two results; the new shared state for all downstream builds to consume and the Operation Graph that encodes the actual build logic a DAG. This stage will contain its own incremental build checks to re-use a cached form of the two outputs if available and none of the inputs have changed (NOTE: Note implemented yet, but can be simulated with the undocumented -skipGenerate flag).

4. **Build Evaluate** -
    The final stage of the build is to evaluate the build Operations that were generated from the build Tasks. These commands contain the executable and arguments to pass in, as well as the input and output files that will be used to perform incremental builds. During execution of each Operation the Engine will monitor the actual file system access (using Detours on Windows, open question for other platforms) to build a complete set of input and output files to be used for a guaranteed incremental build. The initial implementation will use a very simple time-stamp based incremental build that can be extended to use hashing of file contents in the future.

## Package Manager
You may have noticed that nothing about the build explicitly deals with the integration of a public feed of packages. Because each individual projects build is isolated and self contained, a dependency reference can easily be migrated from a direct directory reference, for local projects, to a name@version pair that will be resolved to a published snapshot of a public project. The CLI application will consume a rest API from a hosted web service that allows for users to install other projects and publish the code they would like to share with ease. The build Engine will then have a small amount of integration logic that knows where to look when resolving dependencies that reference a public package that will be installed to a known location. It should be noted that these public dependency references can be for both runtime and developer dependencies. This will allow for shared packages to contain custom build logic and for the creation of shared build Extensions to augment the built in build Tasks.

## Open Questions
* "Top level incremental builds" - We can be faster!!! In the design for the [tup build](http://gittup.org/tup/build_system_rules_and_algorithms.pdf) system they define what they call **Beta Build Systems** which rely on the inverse lookup of taking the known changed files to lookup which build steps need to be rerun. This may not be enough for Soup since there is a decent amount of work to be done during Generate which does not involve the Operation calls. I would like to adapt this design to track the exhaustive set of files used for a given package to implement a top level incremental build that can skip all packages that are not changed. It will require a daemon to monitor file access between calls, but it will be worth it for large projects. 