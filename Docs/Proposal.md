# A New Way to Build and Collaborate
You may already be skeptical - "Why do we need yet another competing solution for building our code?". The concern that this would further fragment our community is valid. However, if you are willing to give the following proposal a chance, I think you will find that these ideas have the possibility to create a solution that will resolve many issues plaguing our community today with minimal impact to existing solutions.

I have spent a majority of my career as a software engineer advocating to not reinvent what can instead be borrowed and extended from others. This has made the process of presenting my ideas for this project a challenge. At first glance, it seems like the former is a direct contradiction to the latter. The reality is, we are at a unique point in the lifetime of C++ where a new build system has the opportunity to resolve the primary issues that imped the current language from reaching its full potential. From the programmer writing their very first "Hello World!," to the most weathered of coders, I believe that C++ has the ability to be the best collaborative experience for everyone.

With the release of C++ 20 this year, we will finally be getting our hands on the long awaited (and controversial) Modules support. This feature will allow C++ builds to finally have a clean binary separation between individual projects. This in turn, will open the door to fixing many of the problems present in building and sharing C++ code today. At the same time, migrating our code to support Modules will require a substantial amount of work that will break backward compatibility with legacy code bases. That means this is the ideal time to consider a major shift in what tooling we use as a community.

In the remaining sections of this document, I outline a general overview of the key issues present in building and sharing our code today. Then, I present a design for a new build system, that leverages Modules at its core, to create a new way of collaborating around the open source community.

## Sharing Code
Beyond the normal complexity of all programming languages, C++ has additional facets that make it especially hard to build and share libraries with others. There are three primary aspects that make this a challenge for C++: one, it has a single specification with multiple compiler implementations, two, it is a compiled language, and three, it inherited the C preprocessor.

### Specification
Unlike many other languages available today, C++ is the only language to have no first party compiler. This affords us the opportunity to have multiple compilers from different vendors, and allows for targeting a large variety of architectures. All that to say, in order to share code with the C++ community as a whole, one would have to navigate around platform specific logic, and have a unique setup for each compiler to ensure the build works correctly. Although this isn't too difficult of a problem for a good build system to handle, it does require some integration work to support new compiler vendors. This is an area that has seen the largest improvements to C++ in the last decade â€” The continued evolution of the Standard Library specification as an abstraction over common platform functionality has greatly reduced, but not eliminated, the complexity for developing cross platform solutions.

### Compiled
The downfall of having such an array of compiler implementations, is compounded by the fact that C++ is compiled directly to the assembly for the target machine that will execute the code. C++ puts no constraints on how a compiler does this mapping. As a result, the [Application Binary Interface (ABI)](https://en.wikipedia.org/wiki/Application_binary_interface) between two compilers (and sometimes between versions of the same compiler) are not compatible with each other. This requires that we must ensure all objects are generated using the same compiler, or that special care be taken to work around these incompatibilities using strict [design practices](PopularABIWorkarounds.md).

### Preprocessor
The C preprocessor was, until now, a point of failure that could not be protected against by any build system when integrating with external projects. Until C++ 20 Modules the only way to share a symbol was to place a declaration in a shared header file that would be included by both the implementation and all of the translation units that wish to consume it. However, when a header file is included with a different set of preprocessor definitions, between usage and implementation, problems often occur. These header files can also "leak" their internal definitions into consumer code. At best, this will result in a compiler or linker error. At worst, it will result in a fun [one definition rule](https://en.wikipedia.org/wiki/One_Definition_Rule) violation or other subtle runtime error. By utilizing Modules as a clean binary separation between individual projects we can eliminate the possibility of accidentally introducing preprocessor related issues.

### BONUS - Language Version
A vital concern with sharing code between different projects is incompatible language standards. It is relatively straightforward to pull most code that targets earlier versions of a language into a project with a newer version; however, the inverse is not true. For projects that are large enough, a lot of work is put into using conditional compilation to ensure compatibility for all supported language versions. This is another instance where C++ Modules has the possibility to be a vehicle to solve this problem in a generic way. By using the Binary Interface layer to allow for inter-module libraries we could conceptually allow for different language versions internal to the individual projects that still share a compatible interface layer. The best we can do for now is create a build system and ecosystem that utilizes Modules as an inter-project communication channel and hope that the standards committee creates subsequent versions of the language that introduce breaking changes to the language in such a way that maintains the binary interface layer compatibility.

## Proposal
Modules will not solve all of our problems by itself. It is necessary that we also define and create a build system with a clear set of priorities to fully take advantage of the new functionality. In the remainder of this document, I outline the **Requirements** and **Goals** for this new proposed build system, and give a brief overview of it's core design.

### Requirements
The following set of requirements cannot be compromised. The order does not indicate a priority; but, the final system would be deemed a failure if we are unable to fulfill any one of them.

1) Reproducible - Core to any build system is the requirement that builds be **deterministic** and **reproducible**. No matter how well a system is designed and implemented, teams will not be able to utilize it unless they can trust that it will always produce the same result independent of who builds it, where they build it and when.

2) Extensible - A build system should be able to support the requirements of **all** projects. It should strive to work out of the box for a majority of scenarios, but must have an extensibility framework that allows build architects to write their own custom build logic when the built in functionality does not meet their needs.

3) Isolation - This is a uniquely important requirement for C++. This is a direct result of the issues present in the language issues outlined above. Isolated builds means that one project cannot influence or be influenced by another build, intentionally or by accident, except through explicit structured channels.

### Goals
While the goals are not hard requirements, they are always kept at the forefront when making any design or implementation decision. These items are in priority order:

1) Collaborative - Writing code is very rarely done in isolation. The largest goal for this build system is to be able to work seamlessly within a team and with external dependencies.

2) Simple - When fulfilling the above requirements the secondary priority is always simplicity and usability. This means that the standard user will get the best experience possibly for both setup and usage. Some extra complexity is allowed in exchange for performance gains in the internal implementation and the extensibility framework.

3) Fast - The inner developer loop is very important to the productivity of an engineer. To this end, the build system should focus heavily on the performance of an incremental build and, to a lesser extent, ensure the full build is as fast as possible.

4) Customizable - How a project is built is often a matter of personal preference (or legacy requirement). Where allowable, the build system should be customizable to allow for overriding default settings so it does not conflict with the ability to easily build single projects as a part of the greater ecosystem.

## Design
This build system, called **SOUP**, will utilize a declarative **Recipe** file as an easy to understand definition for an individual Package. This file will be the primary way to tell Soup about your project. The core command line application will be used to invoke the build and provide extra configuration parameters. Internally, Soup uses a **Task** execution engine to run build Tasks in their requested order and exposes a registration mechanism to allow for C++ "Extension" Dynamic Libraries to run arbitrary code during the build. The Tasks are expected to generate a [Directed Acyclic Graph (DAG)](https://en.wikipedia.org/wiki/Directed_acyclic_graph) of build **Operations** that make up the actual build. Theses Operations will be executed to produce the final build result. The primary design consists of five key components: the command line application, the build definition, the build engine, and the package repository.

### Application
The [Command Line Interface (CLI)](CLI.md) is the first thing a user will see when they interact with the Soup build system. The CLI is primarily there to take user input through a set of parameters and flags to pass temporary configuration values into the build execution. While important, it is fairly straightforward to design and will be left open to evolve through use. 

### Definition
The build definition, which will be implemented through a declarative Recipe configuration file is how the user will configure their project. The Recipe file will utilize the [toml](https://github.com/toml-lang/toml) language as a clean, human readable configuration definition that supports a core set of data types. The file can be thought of as a simple property bag for getting shared parameters passed into the build system for an individual package. There are a few "known" property values that will be used within the build engine itself; however, the entire contents will be provided as initial input to the build engine.

### Engine
The build Engine is responsible for recursively building all transitive dependencies, facilitating the registration and execution of build Tasks, and executing all requirement build Operations. All build logic will be contained in Tasks and all build execution will be performed in Operations. Having this extra layer of separation between the build runtime and the build execution allows for build Extensions to get fast incremental build support for "free" and will allow for future performance improvements without introducing breaking changes into the Extension Framework. 

This work can be broken down into five phases:
1. **Parse Recipe** - The Recipe toml file is read from disk and parsed into a property bag.
2. **Build Dependencies** - The Engine will use the known property lists "Dependencies" and "DevDependencies" to recursively build all transitive runtime and development dependencies starting at phase one. The Engine will maintain a communication channel between parent and children project builds, to allow for passing shared parameters down and output objects back up using property bags.
3. **Build Extensions** - The Engine will then discover and invoke the predefined C method that is exported from all registered Extension DLLs. A single predefined Extension DLL, that is distributed with the CLI executable, contains the Tasks that encode the default build logic that will allow for building projects for a majority of scenarios.
4. **Run Tasks** - A Build Task will consist of a unique name, lists of other Tasks that must be run before and after, and a single execute entry point. The build Tasks will communicate with the build Engine itself through a strict interface layer to maintain a compatible ABI that will allow the CLI executable to work with the source compiled development dependencies from a different compiler. The build Engine will invoke all registered build Tasks in their requested order as defined by the run Before/After lists. The Tasks can influence each other by reading and writing properties to and from the active state (a shared property bag). A build Task should not actually perform any build commands itself (compile/link/copy/etc.), it will instead generate build Operations which are self contained executable definitions with input/output files.
5. **Run Operations** - The final stage of the build is to execute the build Operations that were generated from the build Tasks. These commands contain the executable and parameters to pass in, as well as, the input and output files that will be used to perform incremental builds. There is currently a very simple time-stamp based incremental build that relies on the compiler generated include list. There is an open question of which project will be used to replace this temporary solution. The current best choices are either [BuildXL](https://github.com/microsoft/BuildXL) or possibly [Ninja](https://github.com/ninja-build/ninja).

### Repository
You may have noticed that nothing about the build explicitly deals with the integration of a public feed of packages. Because each individual projects build is isolated and self contained, the key concept is that a dependency reference can easily be migrated from a direct directory reference for local projects to a name@version pair that will be resolved to a published snapshot of a public project. The CLI application can then consume a rest API from a hosted web service that allows for users to install other projects and publish the code they would like to share with ease. The build Engine will then have a small amount of integration logic that knows where to look when resolving dependencies that reference a public package. It should be noted that these public dependency references can be for both runtime and developer dependencies. This will allow for shared packages to contain custom build logic and for the creation of shared build Extensions to augment the built in build Tasks.

## Summary
Transitioning the entire C++ community to a new ecosystem of build tooling will require a great deal of effort. However, C++20 presents a unique opportunity to do so. Migrating to take advantage of Modules is a non-trivial breaking change. By aligning this transition with the emergence of a new build system that was designed explicitly for use in this modern era, we can finally get to a place where C++ is an exceptional language for collaborating with others.

Check out some [Samples](Samples.md) to get a better idea of how all of this will work in practice! While the core command line application is ready for small scale testing, there is a hard requirement on C++20 compiler support, which has limited the initial implementation to MSVC and Windows for now. Support for Linux/Mac builds will be created as soon as the compiler support is available. The highest priority now is to get feedback from the community to discover and resolve any design issues as soon as possible.